
import { GoogleGenAI, Type, Schema, GenerateContentResponse } from "@google/genai";
import { Difficulty, GeneratedMCQResponse, GeneratedStationResponse, MentorResponse, StationItem } from "../types";

const apiKey = process.env.API_KEY || '';

// Initialize Gemini Client
const ai = new GoogleGenAI({ apiKey });

// UPGRADE: Use Gemini 3 Pro for superior reasoning, thinking capabilities, and context handling
const modelId = "gemini-3-pro-preview";

interface ContentFile {
    content: string;
    isText: boolean;
}

// Token Limits (Approximate 1 token = 4 chars)
// Limit total text input to ~3.5M characters (~875k tokens) to be safe under the 1M token limit
const LIMIT_THEORY_CHARS = 2400000; // ~600k tokens
const LIMIT_CLINICAL_CHARS = 1000000; // ~250k tokens
const LIMIT_SAMPLE_CHARS = 200000; // ~50k tokens

// --- RETRY LOGIC HELPER ---
const wait = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

async function retryGeminiCall<T>(
  call: () => Promise<T>,
  retries: number = 3,
  initialDelay: number = 2000
): Promise<T> {
  let lastError: any;
  
  for (let i = 0; i < retries; i++) {
    try {
      return await call();
    } catch (error: any) {
      lastError = error;
      
      // Check for Rate Limit (429) or Quota Exceeded or Service Unavailable (503)
      const isRateLimit = 
        error.status === 429 || 
        error.status === 503 ||
        (error.message && (
          error.message.includes("429") || 
          error.message.includes("quota") || 
          error.message.includes("RESOURCE_EXHAUSTED") ||
          error.message.includes("Overloaded")
        ));

      if (isRateLimit) {
        if (i === retries - 1) break; // Don't wait on the last fail
        console.warn(`Gemini Rate Limit/Overload hit. Retrying in ${initialDelay}ms... (Attempt ${i + 1}/${retries})`);
        await wait(initialDelay);
        initialDelay *= 2; // Exponential backoff
      } else {
        throw error; // Not a rate limit error, throw immediately
      }
    }
  }
  
  // If we get here, we exhausted retries
  const cleanMsg = lastError?.message || "Unknown error";
  if (cleanMsg.includes("quota") || cleanMsg.includes("RESOURCE_EXHAUSTED")) {
      throw new Error("ƒê√£ h·∫øt h·∫°n m·ª©c s·ª≠ d·ª•ng AI (Quota Exceeded). Vui l√≤ng ki·ªÉm tra g√≥i c∆∞·ªõc ho·∫∑c th·ª≠ l·∫°i v√†o ng√†y mai.");
  }
  throw new Error("H·ªá th·ªëng AI ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau v√†i gi√¢y.");
}

export const generateMCQQuestions = async (
  topic: string,
  count: number,
  difficulties: Difficulty[],
  files: { theory?: ContentFile[]; clinical?: ContentFile[]; sample?: ContentFile[] } = {}
): Promise<GeneratedMCQResponse> => {
  if (!apiKey) throw new Error("API Key is missing");

  // 1. Construct the prompt with STRICT instructions for file usage
  let systemInstruction = `
    B·∫°n l√† m·ªôt gi√°o s∆∞ Y khoa h√†ng ƒë·∫ßu. Nhi·ªám v·ª• c·ªßa b·∫°n l√† t·∫°o ƒë·ªÅ thi tr·∫Øc nghi·ªám gi·∫£i ph·∫´u h·ªçc ch·∫•t l∆∞·ª£ng cao.
    
    QUY T·∫ÆC PH√ÇN T√çCH T√ÄI LI·ªÜU (TU√ÇN TH·ª¶ TUY·ªÜT ƒê·ªêI):
    1. D·ªÆ LI·ªÜU L√ù THUY·∫æT (Theory): CH·ªà ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o c√°c c√¢u h·ªèi thu·ªôc m·ª©c ƒë·ªô: 
       - ${Difficulty.REMEMBER} (Ghi nh·ªõ)
       - ${Difficulty.UNDERSTAND} (Hi·ªÉu)
       - ${Difficulty.APPLY} (V·∫≠n d·ª•ng th·∫•p)
       AI c·∫ßn ph√¢n bi·ªát r√µ ba m·ª©c ƒë·ªô n√†y d·ª±a tr√™n ƒë·ªô s√¢u c·ªßa ki·∫øn th·ª©c l√Ω thuy·∫øt.

    2. D·ªÆ LI·ªÜU L√ÇM S√ÄNG (Clinical): CH·ªà ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o c√¢u h·ªèi m·ª©c ƒë·ªô:
       - ${Difficulty.CLINICAL} (L√¢m s√†ng/Ca b·ªánh)
       C√¢u h·ªèi l√¢m s√†ng b·∫Øt bu·ªôc ph·∫£i l√† c√°c Case Study (t√¨nh hu·ªëng b·ªánh nh√¢n) c·ª• th·ªÉ, y√™u c·∫ßu ch·∫©n ƒëo√°n, ti√™n l∆∞·ª£ng ho·∫∑c gi·∫£i ph·∫´u ·ª©ng d·ª•ng th·ª±c t·∫ø.

    3. ƒê·ªÄ THI M·∫™U: N·∫øu c√≥, h√£y h·ªçc phong c√°ch ƒë·∫∑t c√¢u h·ªèi v√† format t·ª´ ƒë√≥.

    C·∫§U TR√öC ƒê·ªÄ THI:
    - T·ªïng s·ªë c√¢u: ${count} c√¢u.
    - Ch·ªß ƒë·ªÅ: "${topic}".
    - C√°c m·ª©c ƒë·ªô kh√≥ y√™u c·∫ßu: ${difficulties.join(', ')}.
    - M·ªói c√¢u h·ªèi c√≥ 4 l·ª±a ch·ªçn, 1 ƒë√°p √°n ƒë√∫ng.
    - Gi·∫£i th√≠ch: Ph·∫£i c·ª±c k·ª≥ chi ti·∫øt, tr√≠ch d·∫´n l√Ω do t·∫°i sao ƒë√∫ng/sai.
  `;

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      questions: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            question: { type: Type.STRING },
            options: { type: Type.ARRAY, items: { type: Type.STRING } },
            correctAnswer: { type: Type.STRING },
            explanation: { type: Type.STRING },
            difficulty: { type: Type.STRING, description: "M·ª©c ƒë·ªô kh√≥ ch√≠nh x√°c (Ghi nh·ªõ, Hi·ªÉu, V·∫≠n d·ª•ng th·∫•p, L√¢m s√†ng)" },
          },
          required: ["question", "options", "correctAnswer", "explanation", "difficulty"],
        },
      },
    },
    required: ["questions"],
  };

  // 2. Construct Multimodal Parts with Explicit Context Separation
  const parts: any[] = [];

  // Helper to add and truncate content parts
  const addContentParts = (fileItems: ContentFile[] | undefined, sectionTitle: string, usageInstruction: string, charLimit: number) => {
    if (!fileItems || fileItems.length === 0) return;

    parts.push({ text: `\n=== B·∫ÆT ƒê·∫¶U PH·∫¶N: ${sectionTitle} ===\nCH·ªà D·∫™N: ${usageInstruction}\n` });
    
    let currentChars = 0;

    for (const item of fileItems) {
        // Stop adding files if limit is reached
        if (currentChars >= charLimit) {
             parts.push({ text: `\n[C·∫¢NH B√ÅO: ƒê√£ ng∆∞ng t·∫£i th√™m t√†i li·ªáu ph·∫ßn n√†y do v∆∞·ª£t qu√° gi·ªõi h·∫°n b·ªô nh·ªõ cho ph√©p]\n` });
             break;
        }

        if (item.content) {
            if (item.isText) {
                // Case 1: Extracted Text
                let textToAdd = item.content;
                const remaining = charLimit - currentChars;

                if (textToAdd.length > remaining) {
                    textToAdd = textToAdd.substring(0, remaining) + "\n\n[...N·ªôi dung file n√†y ƒë√£ b·ªã c·∫Øt b·ªõt do gi·ªõi h·∫°n b·ªô nh·ªõ AI...]";
                }
                
                parts.push({ text: `\n--- FILE CONTENT ---\n${textToAdd}\n` });
                currentChars += textToAdd.length;
            } else {
                // Case 2: Base64 PDF/Image (Only for small files < 20MB)
                // Cannot easily count chars for binary, but assume it takes up context.
                // Check mimeType if available, default to pdf assumption for now.
                const base64Data = item.content.includes('base64,') ? item.content.split('base64,')[1] : item.content;
                parts.push({
                    inlineData: {
                        mimeType: "application/pdf", 
                        data: base64Data
                    }
                });
                // Arbitrary penalty for binary file to avoid infinite loop if mixed
                currentChars += 50000; 
            }
        }
    }
    parts.push({ text: `=== K·∫æT TH√öC PH·∫¶N: ${sectionTitle} ===\n` });
  };

  // Add files with strict limits
  addContentParts(
    files.theory, 
    "T√ÄI LI·ªÜU L√ù THUY·∫æT", 
    `D√πng cho c√¢u h·ªèi m·ª©c ƒë·ªô ${Difficulty.REMEMBER}, ${Difficulty.UNDERSTAND}, ${Difficulty.APPLY}.`,
    LIMIT_THEORY_CHARS
  );
  
  addContentParts(
    files.clinical, 
    "T√ÄI LI·ªÜU L√ÇM S√ÄNG", 
    `CH·ªà D√πng cho c√¢u h·ªèi m·ª©c ƒë·ªô ${Difficulty.CLINICAL} (Case Study).`,
    LIMIT_CLINICAL_CHARS
  );
  
  addContentParts(
    files.sample, 
    "ƒê·ªÄ THI M·∫™U", 
    "Tham kh·∫£o c√°ch ƒë·∫∑t c√¢u h·ªèi.",
    LIMIT_SAMPLE_CHARS
  );

  // Add the final trigger prompt
  parts.push({ text: `H√£y "Suy nghƒ©" (Thinking) k·ªπ v·ªÅ ph√¢n ph·ªëi c√¢u h·ªèi, sau ƒë√≥ so·∫°n th·∫£o ${count} c√¢u h·ªèi tr·∫Øc nghi·ªám v·ªÅ ch·ªß ƒë·ªÅ "${topic}" theo ƒë√∫ng ƒë·ªãnh d·∫°ng JSON ƒë√£ y√™u c·∫ßu.` });

  try {
    const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
      model: modelId,
      contents: {
        parts: parts,
      },
      config: {
        systemInstruction: systemInstruction,
        responseMimeType: "application/json",
        responseSchema: schema,
        // Thinking Budget: Allows the model to plan the question distribution and validate clinical logic
        thinkingConfig: { thinkingBudget: 2048 }, 
      },
    }));

    let text = response.text;
    if (!text) throw new Error("No response from AI");
    
    // Robust JSON Cleaning
    const jsonBlockMatch = text.match(/```json\s*([\s\S]*?)\s*```/);
    if (jsonBlockMatch) {
        text = jsonBlockMatch[1];
    } else {
        text = text.replace(/```json/g, '').replace(/```/g, '');
    }
    
    text = text.trim();

    let parsed: any;
    try {
      parsed = JSON.parse(text);
    } catch (e) {
      console.error("Failed to parse JSON:", text);
      throw new Error("AI returned invalid JSON format. Please try again.");
    }

    if (!parsed || typeof parsed !== 'object') {
       throw new Error("Invalid response structure");
    }

    if (!Array.isArray(parsed.questions)) {
        throw new Error("Response missing 'questions' array");
    }

    return parsed as GeneratedMCQResponse;

  } catch (error: any) {
    console.error("Gemini API Error:", error);
    
    // Pass through the specific rate limit error thrown by retryGeminiCall
    if (error.message && (error.message.includes("qu√° t·∫£i") || error.message.includes("h·∫øt h·∫°n m·ª©c"))) {
        throw error;
    }

    // Enhance token error
    if (error.message && error.message.includes("token count exceeds")) {
        throw new Error("T·ªïng dung l∆∞·ª£ng t√†i li·ªáu qu√° l·ªõn v∆∞·ª£t qu√° gi·ªõi h·∫°n c·ªßa AI. Vui l√≤ng b·ªõt file ho·∫∑c d√πng file nh·ªè h∆°n.");
    }
    
    throw error;
  }
};

// --- Generate Spot Test Question from Image (Vision) ---
export interface StationQuestionResponse {
    isValid: boolean;
    questions?: {
        questionText: string;
        correctAnswer: string;
        explanation: string;
    }[];
}

export const generateStationQuestionFromImage = async (base64Image: string, topic?: string): Promise<StationQuestionResponse> => {
    const systemInstruction = `
    B·∫°n l√† gi√°m kh·∫£o thi ch·∫°y tr·∫°m (Spot Test) Gi·∫£i ph·∫´u h·ªçc c·ª±c k·ª≥ nghi√™m t√∫c.
    B·∫°n s·∫Ω ƒë∆∞·ª£c cung c·∫•p m·ªôt h√¨nh ·∫£nh t·ª´ t√†i li·ªáu PDF.
    
    NHI·ªÜM V·ª§ 1: KI·ªÇM TRA T√çNH H·ª¢P L·ªÜ & ƒê√öNG CH·ª¶ ƒê·ªÄ (QUAN TR·ªåNG NH·∫§T)
    - H√¨nh ·∫£nh H·ª¢P L·ªÜ (isValid = true) PH·∫¢I TH·ªéA M√ÉN C·∫¢ 2 ƒêI·ªÄU KI·ªÜN:
       1. L√† h√¨nh gi·∫£i ph·∫´u minh h·ªça r√µ r√†ng, c√≥ ƒë∆∞·ªùng ch·ªâ d·∫´n (leader lines) ho·∫∑c s·ªë ch√∫ th√≠ch.
       2. N·ªòI DUNG H√åNH ·∫¢NH PH·∫¢I LI√äN QUAN ƒê·∫æN CH·ª¶ ƒê·ªÄ: "${topic || 'Gi·∫£i ph·∫´u h·ªçc'}".
          - N·∫øu ch·ªß ƒë·ªÅ l√† "Tim", nh∆∞ng h√¨nh l√† "X∆∞∆°ng ƒë√πi" -> isValid = false.
          - N·∫øu ch·ªß ƒë·ªÅ l√† "Th·∫ßn kinh", nh∆∞ng h√¨nh ch·ªâ c√≥ "C∆° b·∫Øp" -> isValid = false.

    - H√¨nh ·∫£nh KH√îNG H·ª¢P L·ªÜ (isValid = false): 
       + Trang s√°ch ch·ªâ to√†n ch·ªØ (Text-only).
       + M·ª•c l·ª•c, b√¨a s√°ch.
       + H√¨nh ·∫£nh sai ch·ªß ƒë·ªÅ.
       + H√¨nh ·∫£nh qu√° m·ªù.

    NHI·ªÜM V·ª§ 2: RA ƒê·ªÄ (Ch·ªâ khi isValid = true)
    
    Quy t·∫Øc ra ƒë·ªÅ:
    1. Ch·ªçn M·ªòT c·∫•u tr√∫c gi·∫£i ph·∫´u quan tr·ªçng nh·∫•t trong h√¨nh LI√äN QUAN ƒê·∫æN CH·ª¶ ƒê·ªÄ "${topic}".
    2. ƒê·∫∑t c√¢u h·ªèi ƒë·ªãnh danh tr·ª±c ti·∫øp. V√≠ d·ª•: "C·∫•u tr√∫c ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh l√† g√¨?", "Chi ti·∫øt s·ªë X l√† g√¨?".
    3. ƒê√°p √°n ph·∫£i l√† T√™n gi·∫£i ph·∫´u ch√≠nh x√°c (Ti·∫øng Vi·ªát).
    4. Gi·∫£i th√≠ch ng·∫Øn g·ªçn.

    Output JSON format:
    {
      "isValid": boolean,
      "questions": [
        {
          "questionText": "C√¢u h·ªèi...",
          "correctAnswer": "T√™n c·∫•u tr√∫c",
          "explanation": "Gi·∫£i th√≠ch..."
        }
      ]
    }
    `;

    const prompt = topic 
        ? `Ki·ªÉm tra xem h√¨nh n√†y c√≥ ch·ª©a c·∫•u tr√∫c gi·∫£i ph·∫´u thu·ªôc ch·ªß ƒë·ªÅ "${topic}" kh√¥ng. N·∫øu c√≥, h√£y t·∫°o 1 c√¢u h·ªèi tr·∫°m.` 
        : "Ki·ªÉm tra xem ƒë√¢y c√≥ ph·∫£i l√† h√¨nh gi·∫£i ph·∫´u h·ª£p l·ªá kh√¥ng. N·∫øu c√≥, h√£y t·∫°o 1 c√¢u h·ªèi tr·∫°m.";

    try {
        // Remove header if present to get raw base64
        const cleanBase64 = base64Image.includes('base64,') ? base64Image.split('base64,')[1] : base64Image;
        
        const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
            model: "gemini-2.5-flash", // Use Flash for Vision speed/efficiency
            contents: { 
                role: 'user', 
                parts: [
                    { text: prompt },
                    { inlineData: { mimeType: 'image/jpeg', data: cleanBase64 } }
                ] 
            },
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        isValid: { type: Type.BOOLEAN },
                        questions: {
                            type: Type.ARRAY,
                            items: {
                                type: Type.OBJECT,
                                properties: {
                                    questionText: { type: Type.STRING },
                                    correctAnswer: { type: Type.STRING },
                                    explanation: { type: Type.STRING }
                                },
                                required: ["questionText", "correctAnswer", "explanation"]
                            }
                        }
                    },
                    required: ["isValid"]
                }
            }
        }));

        let text = response.text || "";
        text = text.replace(/```json/g, '').replace(/```/g, '').trim();
        const parsed = JSON.parse(text) as StationQuestionResponse;
        
        return parsed;
    } catch (e: any) {
        console.error("Vision API Error", e);
        // IMPORTANT: If we hit a rate limit or quota limit even after retries, we MUST throw 
        // to stop the loop in StationMode.
        if (e.message && (e.message.includes("qu√° t·∫£i") || e.message.includes("quota") || e.message.includes("429"))) {
            throw e;
        }
        // For other errors (e.g. bad image format), just return invalid so we skip this page
        return { isValid: false, questions: [] };
    }
};

export const analyzeResultWithOtter = async (
    topic: string,
    stats: Record<string, { correct: number, total: number }>
): Promise<MentorResponse> => {
    // Format stats into a readable string for the prompt
    const statsDescription = Object.entries(stats)
        .map(([diff, val]) => {
             const pct = val.total > 0 ? Math.round((val.correct / val.total) * 100) : 0;
             return `- ${diff}: ${val.correct}/${val.total} c√¢u (${pct}%)`;
        })
        .join('\n');

    const prompt = `
    ƒê√≥ng vai l√† "R√°i c√° nh·ªè" (Little Otter) - m·ªôt gia s∆∞ AI gi·∫£i ph·∫´u h·ªçc c·ª±c k·ª≥ th√¥ng minh, h√†i h∆∞·ªõc, hay d√πng emoji ü¶¶.
    
    H·ªçc vi√™n v·ª´a l√†m b√†i thi v·ªÅ ch·ªß ƒë·ªÅ: "${topic}".
    
    D·ªÆ LI·ªÜU K·∫æT QU·∫¢ (STATS):
    ${statsDescription}
    
    NHI·ªÜM V·ª§ C·ª¶A B·∫†N (Y√™u c·∫ßu ƒë·ªô chi ti·∫øt cao):
    1. PH√ÇN T√çCH S√ÇU (Deep Analysis): 
       - D·ª±a v√†o stats, nh·∫≠n x√©t v·ªÅ nƒÉng l·ª±c hi·ªán t·∫°i.
       - ƒê∆∞a ra l·ªùi nh·∫≠n x√©t d√≠ d·ªèm nh∆∞ng th·∫•m th√≠a.

    2. ƒê√ÅNH GI√Å CHI TI·∫æT:
       - ƒêi·ªÉm m·∫°nh: C√°c ph·∫ßn l√†m t·ªët.
       - ƒêi·ªÉm y·∫øu: C√°c ph·∫ßn hay sai.

    3. L·ªò TR√åNH C·∫¢I THI·ªÜN (Actionable Roadmap - C·ª∞C K·ª≤ QUAN TR·ªåNG):
       - H√£y thi·∫øt k·∫ø 4 b∆∞·ªõc h√†nh ƒë·ªông c·ª• th·ªÉ ƒë·ªÉ kh·∫Øc ph·ª•c ƒëi·ªÉm y·∫øu nh·∫•t.
       - KH√îNG ƒê∆Ø·ª¢C vi·∫øt chung chung nh∆∞ "H·ªçc l·∫°i l√Ω thuy·∫øt" hay "ƒê·ªçc th√™m s√°ch".
       - H√ÉY VI·∫æT C√ÅC K·ª∏ THU·∫¨T C·ª§ TH·ªÇ, v√≠ d·ª•: 
         + "V·∫Ω l·∫°i s∆° ƒë·ªì ƒë√°m r·ªëi th·∫ßn kinh c√°nh tay 3 l·∫ßn b·∫±ng tr√≠ nh·ªõ (Active Recall)."
         + "So s√°nh nguy√™n ·ªßy/b√°m t·∫≠n c·ªßa nh√≥m c∆° g·∫•p v√† du·ªói (Comparative Study)."
         + "Gi·∫£i th√≠ch c∆° ch·∫ø b·ªánh sinh c·ªßa ca l√¢m s√†ng X cho ng∆∞·ªùi kh√°c nghe (Feynman Technique)."
         + "T·∫°o Flashcard Anki cho c√°c nh√°nh b√™n ƒë·ªông m·∫°ch."
       - M·ª•c "details" ph·∫£i d√†i kho·∫£ng 2-3 c√¢u, h∆∞·ªõng d·∫´n c√°ch l√†m chi ti·∫øt.

    Output JSON format:
    {
      "analysis": "L·ªùi nh·∫≠n x√©t chung...",
      "strengths": ["ƒêi·ªÉm m·∫°nh 1", "ƒêi·ªÉm m·∫°nh 2"],
      "weaknesses": ["ƒêi·ªÉm y·∫øu 1", "ƒêi·ªÉm y·∫øu 2"],
      "roadmap": [
         { "step": "T√™n ph∆∞∆°ng ph√°p (VD: K·ªπ thu·∫≠t V·∫Ω h·ªìi t∆∞·ªüng)", "details": "H∆∞·ªõng d·∫´n chi ti·∫øt c√°ch th·ª±c hi·ªán..." }
      ]
    }
    `;

    try {
        const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
            model: "gemini-3-pro-preview",
            contents: { role: 'user', parts: [{ text: prompt }] },
            config: {
                responseMimeType: "application/json",
                thinkingConfig: { thinkingBudget: 2048 } // Increased budget for detailed roadmap planning
            }
        }));

        let text = response.text || "";
        text = text.replace(/```json/g, '').replace(/```/g, '').trim();
        return JSON.parse(text) as MentorResponse;
    } catch (e) {
        console.error(e);
        return {
            analysis: "√öi cha! R√°i c√° ƒëang b·∫≠n b·∫Øt c√° n√™n kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c r·ªìi. Th·ª≠ l·∫°i sau nh√©! ü¶¶",
            strengths: [],
            weaknesses: [],
            roadmap: []
        };
    }
};

export const chatWithOtter = async (history: {role: 'user' | 'model', text: string, image?: string}[], message: string, image?: string): Promise<string> => {
    // Use Flash for speed in chat
    const model = "gemini-2.5-flash"; 
    
    const systemInstruction = `B·∫°n l√† "R√°i c√° nh·ªè" (Little Otter) ü¶¶ - m·ªôt tr·ª£ l√Ω ·∫£o chuy√™n v·ªÅ GI·∫¢I PH·∫™U H·ªåC (Anatomy).
    
    T√çNH C√ÅCH & PHONG C√ÅCH TR·∫¢ L·ªúI:
    - Vui v·∫ª, th√¢n thi·ªán, nh∆∞ng c·ª±c k·ª≥ chuy√™n nghi·ªáp v·ªÅ ki·∫øn th·ª©c y khoa.
    - D√πng emoji (ü¶¶, ü¶¥, üß†) h·ª£p l√Ω ƒë·ªÉ t·∫°o c·∫£m gi√°c g·∫ßn g≈©i.
    
    QUY T·∫ÆC ƒê·ªäNH D·∫†NG VƒÇN B·∫¢N (QUAN TR·ªåNG):
    1. TR√åNH B√ÄY G·ªåN G√ÄNG:
       - S·ª≠ d·ª•ng **in ƒë·∫≠m** (bold) CH·ªà cho c√°c t·ª´ kh√≥a ch√≠nh (thu·∫≠t ng·ªØ gi·∫£i ph·∫´u).
       - H·∫†N CH·∫æ D√ôNG qu√° nhi·ªÅu k√Ω t·ª± # (header) n·∫øu ƒëo·∫°n vƒÉn ng·∫Øn.
       - S·ª≠ d·ª•ng g·∫°ch ƒë·∫ßu d√≤ng (-) ƒë·ªÉ li·ªát k√™ √Ω.
       - KH√îNG d√πng qu√° nhi·ªÅu k√Ω t·ª± ƒë·∫∑c bi·ªát g√¢y r·ªëi m·∫Øt (** kh√¥ng c·∫ßn thi·∫øt th√¨ ƒë·ª´ng d√πng).
    
    2. C·∫§U TR√öC:
       - T√°ch ƒëo·∫°n ng·∫Øn, d·ªÖ ƒë·ªçc.
       - T·∫≠p trung v√†o th√¥ng tin ch√≠nh x√°c, tr√°nh lan man.
    
    NHI·ªÜM V·ª§:
    - Gi·∫£i ƒë√°p m·ªçi c√¢u h·ªèi v·ªÅ c·∫•u tr√∫c gi·∫£i ph·∫´u, ch·ª©c nƒÉng sinh l√Ω, li√™n h·ªá l√¢m s√†ng.
    - Ph√¢n t√≠ch h√¨nh ·∫£nh gi·∫£i ph·∫´u n·∫øu ng∆∞·ªùi d√πng g·ª≠i.
    - T·ª´ ch·ªëi kh√©o l√©o c√°c c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn Y h·ªçc.
    `;

    // Construct Gemini content format
    const contents = history.map(msg => {
        const parts: any[] = [{ text: msg.text }];
        if (msg.image) {
             // Simple base64 extraction assuming data URL
             try {
                 const base64Data = msg.image.includes('base64,') ? msg.image.split('base64,')[1] : msg.image;
                 const mimeType = msg.image.match(/data:([^;]+);base64,/)?.[1] || 'image/jpeg';
                 parts.push({ inlineData: { mimeType, data: base64Data }});
             } catch (e) {
                 console.warn("Could not process history image", e);
             }
        }
        return { role: msg.role, parts };
    });

    const currentParts: any[] = [{ text: message }];
    if (image) {
        try {
            const base64Data = image.includes('base64,') ? image.split('base64,')[1] : image;
            const mimeType = image.match(/data:([^;]+);base64,/)?.[1] || 'image/jpeg';
            currentParts.push({ inlineData: { mimeType, data: base64Data }});
        } catch (e) {
             console.warn("Could not process current image", e);
        }
    }
    contents.push({ role: 'user', parts: currentParts });

    try {
        const response = await retryGeminiCall<GenerateContentResponse>(() => ai.models.generateContent({
            model,
            contents,
            config: { systemInstruction }
        }));
        return response.text || "R√°i c√° ƒëang b∆°i ƒëi ƒë√¢u m·∫•t r·ªìi, kh√¥ng tr·∫£ l·ªùi ƒë∆∞·ª£c... ü¶¶";
    } catch (e) {
        console.error(e);
        return "√öi! M·∫°ng b·ªã ngh·∫Ωn r·ªìi, R√°i c√° kh√¥ng nghe r√µ. B·∫°n h·ªèi l·∫°i nh√©? ü¶¶";
    }
};
